{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce003aa-e35b-4c3e-b462-581af72da604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15d7b9-c3bd-4114-b95a-a0ffda87ba0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "raw_data = \"/Users/shivacharan/retail_sales_analytics/data/raw/sales/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa27b5d3-21cd-45a9-b420-9027219dd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_dated_folder(base_path):\n",
    "    #Gets latest folder in the raw/sales/\n",
    "    folders = [\n",
    "        f for f in os.listdir(base_path)\n",
    "        if os.path.isdir(os.path.join(base_path, f))\n",
    "    ]\n",
    "    \n",
    "    # Try parsing folder names as dates\n",
    "    dated_folders = []\n",
    "    for folder in folders:\n",
    "        try:\n",
    "            date = datetime.strptime(folder, \"%Y-%m-%d\")\n",
    "            dated_folders.append((date, folder))\n",
    "        except ValueError:\n",
    "            continue  # skip non-date folders\n",
    "\n",
    "    if not dated_folders:\n",
    "        raise ValueError(\"No date-formatted folders found\")\n",
    "\n",
    "    latest_folder = max(dated_folders, key=lambda x: x[0])[1]\n",
    "    return os.path.join(base_path, latest_folder)\n",
    "\n",
    "\n",
    "def get_latest_file(dir_path):\n",
    "    #Gets the latest file in a directory.\n",
    "    try:\n",
    "        files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]\n",
    "        if not files:\n",
    "            return None\n",
    "        latest_file = max(files, key=os.path.getmtime)\n",
    "        return latest_file\n",
    "    except Exception as e:\n",
    "         print(f\"An error occurred: {e}\")\n",
    "         return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c798856-c86b-4f79-bb20-abdca5ebd126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/24 15:59:26 WARN Utils: Your hostname, Shivas-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.68.54 instead (on interface en0)\n",
      "25/06/24 15:59:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/24 15:59:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ORDERNUMBER: integer (nullable = true)\n",
      " |-- QUANTITYORDERED: integer (nullable = true)\n",
      " |-- PRICEEACH: double (nullable = true)\n",
      " |-- ORDERLINENUMBER: integer (nullable = true)\n",
      " |-- SALES: double (nullable = true)\n",
      " |-- ORDERDATE: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- QTR_ID: integer (nullable = true)\n",
      " |-- MONTH_ID: integer (nullable = true)\n",
      " |-- YEAR_ID: integer (nullable = true)\n",
      " |-- PRODUCTLINE: string (nullable = true)\n",
      " |-- MSRP: integer (nullable = true)\n",
      " |-- PRODUCTCODE: string (nullable = true)\n",
      " |-- CUSTOMERNAME: string (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- ADDRESSLINE1: string (nullable = true)\n",
      " |-- ADDRESSLINE2: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- POSTALCODE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- TERRITORY: string (nullable = true)\n",
      " |-- CONTACTLASTNAME: string (nullable = true)\n",
      " |-- CONTACTFIRSTNAME: string (nullable = true)\n",
      " |-- DEALSIZE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latest_folder = get_latest_dated_folder(raw_data)\n",
    "latest_file = get_latest_file(latest_folder)\n",
    "\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "       .appName(\"RetailSalesProcessing\")\\\n",
    "       .getOrCreate()\n",
    "\n",
    "if latest_file:\n",
    "    df = spark.read.csv(latest_file, header=True, inferSchema=True) # Read the latest CSV file into a DataFrame\n",
    "    df.printSchema()\n",
    "else:\n",
    "    print(f\"No files found in directory: {latest_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2dc04a-f3a1-442c-85fc-e2e2a2242acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns QTR_ID,Territory\n",
    "df = df.drop(\"QTR_ID\",\"TERRITORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6413024e-c655-463d-9e9b-d33743eb0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with only date\n",
    "df = df.withColumn(\"DATE\", split(col(\"ORDERDATE\"), \" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438ac35c-a5ac-4de4-8ac5-9d853d0b000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"ORDERDATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b12b53e-88f3-4c56-acda-ece0fc4e4311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|           PHONE|  COUNTRY|\n",
      "+----------------+---------+\n",
      "|      2125557818|      USA|\n",
      "|      26.47.1555|   France|\n",
      "|+33 1 46 62 7555|   France|\n",
      "|      6265557265|      USA|\n",
      "|      6505551386|      USA|\n",
      "|      6505556809|      USA|\n",
      "|      20.16.1555|   France|\n",
      "|   +47 2267 3215|   Norway|\n",
      "|      6505555787|      USA|\n",
      "|  (1) 47.55.6555|   France|\n",
      "|    03 9520 4555|Australia|\n",
      "|      2125551500|      USA|\n",
      "|      2015559350|      USA|\n",
      "|      2035552570|      USA|\n",
      "|      40.67.8555|   France|\n",
      "|      6175558555|      USA|\n",
      "|     90-224 8555|  Finland|\n",
      "|      07-98 9555|   Norway|\n",
      "|      2155551555|      USA|\n",
      "|      2125557818|      USA|\n",
      "+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"PHONE\",\"COUNTRY\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5114112e-9f33-4dd0-a219-0498d7dd9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "df_cleaned = df.withColumn(\n",
    "    \"PHONE_CLEAN\", regexp_replace(col(\"PHONE\"), r\"[^0-9+]\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e17579fb-e49b-4aa6-ab7e-abd1b3bf71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------+\n",
      "| PHONE_CLEAN|           PHONE|  COUNTRY|\n",
      "+------------+----------------+---------+\n",
      "|  2125557818|      2125557818|      USA|\n",
      "|    26471555|      26.47.1555|   France|\n",
      "|+33146627555|+33 1 46 62 7555|   France|\n",
      "|  6265557265|      6265557265|      USA|\n",
      "|  6505551386|      6505551386|      USA|\n",
      "|  6505556809|      6505556809|      USA|\n",
      "|    20161555|      20.16.1555|   France|\n",
      "| +4722673215|   +47 2267 3215|   Norway|\n",
      "|  6505555787|      6505555787|      USA|\n",
      "|   147556555|  (1) 47.55.6555|   France|\n",
      "|  0395204555|    03 9520 4555|Australia|\n",
      "|  2125551500|      2125551500|      USA|\n",
      "|  2015559350|      2015559350|      USA|\n",
      "|  2035552570|      2035552570|      USA|\n",
      "|    40678555|      40.67.8555|   France|\n",
      "|  6175558555|      6175558555|      USA|\n",
      "|   902248555|     90-224 8555|  Finland|\n",
      "|    07989555|      07-98 9555|   Norway|\n",
      "|  2155551555|      2155551555|      USA|\n",
      "|  2125557818|      2125557818|      USA|\n",
      "+------------+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.select(\"PHONE_CLEAN\",\"PHONE\",\"COUNTRY\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4387d6-033b-4dae-bb7e-005366d0100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'phone' column\n",
    "df = df_cleaned.drop('phone')\n",
    "\n",
    "# Rename 'phone_clean' to 'phone'\n",
    "df = df.withColumnRenamed('phone_clean', 'PHONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c871b468-2d0e-48e0-9714-08d0b2b2719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a timestamped folder name\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "output_path = f\"/Users/shivacharan/retail_sales_analytics/data/processed/run_{date}\"\n",
    "\n",
    "#Write the data frame to processed folder\n",
    "df.coalesce(1).write.mode(\"overwrite\").parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d4db076-5529-4a8e-b0f4-f2b40748da00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORDERNUMBER',\n",
       " 'QUANTITYORDERED',\n",
       " 'PRICEEACH',\n",
       " 'ORDERLINENUMBER',\n",
       " 'SALES',\n",
       " 'STATUS',\n",
       " 'MONTH_ID',\n",
       " 'YEAR_ID',\n",
       " 'PRODUCTLINE',\n",
       " 'MSRP',\n",
       " 'PRODUCTCODE',\n",
       " 'CUSTOMERNAME',\n",
       " 'ADDRESSLINE1',\n",
       " 'ADDRESSLINE2',\n",
       " 'CITY',\n",
       " 'STATE',\n",
       " 'POSTALCODE',\n",
       " 'COUNTRY',\n",
       " 'CONTACTLASTNAME',\n",
       " 'CONTACTFIRSTNAME',\n",
       " 'DEALSIZE',\n",
       " 'DATE',\n",
       " 'PHONE']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6feaf12-b09d-4ea3-9742-3c944df87c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (airflow_venv)",
   "language": "python",
   "name": "airflow_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
